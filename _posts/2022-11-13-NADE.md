---
layout: post
title: "Neural Autoregressive Distribution Estimator (NADE)"
date: 2022-11-13
author: Janghun Kim, Hyogeun Byun
categories: Auto-regressive
tags: [paper review, PMLR, Auto-Regressive]
use_math: true
published: true
---

Larochelle, Hugo, and Iain Murray. "The neural autoregressive distribution estimator." Proceedings of the fourteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings, 2011.

# 1. Motivation
### What the paper wishes to achieve?
 본 논문이 이루고자 하는 것부터 먼저 설명해보면, high dimensional 한 discrete/binary vector들의 Distribution Estimation 이다. 

### Why is this problem Important?
 이러한 문제들이 중요한 이유는 object들의 joint distribution을 알고있다면, 모든 supervised learning을 포함하여 object 간의 dependency에 대한 모든 질문에 답하기 시작할 수 있기 때문이다.

# 2. Previous Approaches
### Restricted Boltzmann Machines (RBMs)

![image](/assets/NADE_img/rbms.png)

Energy function을 이용하여 Probability를 구하지만, 다양한 문제가 존재한다. 
![image](/assets/NADE_img/rbms2.png)

- Computing partition function $Z는 소규모 network를 제외한 모든 network에서 intractable 하며 근사가 필요로 합니다.
- RMM은 probabilistic system의 일부를 modeling 하는 데 사용할 수 없습니다.
- 학습된 distribution을 평가하는데 어려움이 있습니다.

### Bayesian Networks
![image](/assets/NADE_img/bayesian.png)

다들 아시는 내용이지만, Bayesian Networks의 주요 strategy는 conditionals를 사용하여 distribution을 decomposing하는 것 입니다. 예를 들어, Fully Visible Sigmoid Belief Networks는 다음과 같습니다.

# 3. Neural Autoregressive Distribution Estimator (NADE)
![image](/assets/NADE_img/nade1.png)

NADE의 Architecture는 위와 같으며, 가중치 matrix $W를 공유하는 것을 확인할 수 있습니다. 그리고 next input에 대해서도 이전 Weight를 재활용하는 식의 strategy를 사용하여 computational cost가 절감되며, 빠르게 진행될 수 있다는 것을 알 수 있습니다.

![image](/assets/NADE_img/nade2.png)

NADE 네트워크에서 사용되는 파라미터를 계산한 결과인데 이는 weight matrix를 공유함으로써 파라미터 수가 상당히 적은 것을 확인할 수 있습니다.

NADE의 작동 방식은 다음과 같습니다.
- i 번째 픽셀을 1 ~ i-1 번째 픽셀에 의존하도록 conditionals를 사용합니다.
- 즉, 첫 번째 픽셀의 확률분포는 독립적으로 만들고, 두 번째 픽셀의 확률은 첫 번째 픽셀에 의존하도록 구성
- NADE는 explicit model (생성 + 확률 계산) -> 주어진 입력에 대해 density 계산 가능
- 연속 확률 변수일 때는 마지막 모델에 가우시안 믹스쳐 모델을 사용

![image](/assets/NADE_img/code.png)


# 4. Summary

### Uses the explicit representation of the joint distribution 

### Reduces the number of parameters by sharing weights in the neural network

### Generation is slow because the model generates one pixel at a time

### Possible to speed up the computation by reusing some previous computations

